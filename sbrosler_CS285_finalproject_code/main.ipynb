{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f90654de-213a-4b58-8e11-c6b4b78001f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import importlib\n",
    "import numpy as np\n",
    "from numpy import convolve\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import pickle\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.stats import sem\n",
    "from scipy import signal\n",
    "from scipy.integrate import trapz\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "#from RT import savedData, taskData\n",
    "#from gimutil.signal_analysis import erps\n",
    "#from gimutil.configuration import config\n",
    "#from gimutil.visualization import plotting_tools\n",
    "import os\n",
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from preprocessing import extract_data, preprocess, shuffle_data\n",
    "from default_model import CnnRnn\n",
    "from training import *\n",
    "from evaluation import *\n",
    "from plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b615fe-f2d9-40b8-8c7c-a47b42e88b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c01879-fb01-41a9-8331-6a41799dcfa0",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531c2992-9f01-4e59-9a90-8295663b01e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'data'\n",
    "file_name = 'alphabet_with_fingerflex_data.pkl'\n",
    "\n",
    "# Define the full path\n",
    "full_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "with open(full_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "print(\"Data successfully loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f49f18-d591-4915-8320-2258016a6a00",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f24efb-c2c2-4990-abd8-581ea777ec20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4224, 800, 253)\n",
      "y shape: (4224,)\n"
     ]
    }
   ],
   "source": [
    "X, y, y_num = extract_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc162dd2-9528-4cf4-a88c-cb8816edbdf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape (trials x time x channels):  (4224, 800, 253)\n",
      "\n",
      "Decimating the time series dimension...\n",
      "Downsampled data shape:  (4224, 134, 253)\n",
      "\n",
      "Normalizing data across channels at each time point...\n",
      "\n",
      "Shuffling trial order...\n",
      "\n",
      "Finished preprocessing!\n"
     ]
    }
   ],
   "source": [
    "X, y, y_num = preprocess(X, y, y_num, downsampling_factor = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fffc7c86-d619-4bf5-a085-399f6a7cf9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_labels = np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c1778-a5eb-4549-b79d-b2f89a701b81",
   "metadata": {},
   "source": [
    "# Note:\n",
    "- Run this notebook to execute all four analyses included in my final project. \n",
    "  - **Note:** `main.ipynb` sets `test_splits = 3` for computational speed. \n",
    "  - The final plots in the paper were averaged across at least 10 test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e5de5ac-7b88-4b84-91cb-fa73d9b565cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:2\"\n",
    "test_splits = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347bdd5f-e151-4fb6-88cf-b104a70dc5bb",
   "metadata": {},
   "source": [
    "# Analysis 1: Reward Model Outperforms Default Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46522822-8793-4f9c-a772-2dd8069d5bea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Split 1/3:\n",
      "Training default model...\n",
      "Using device: cuda:2\n",
      "     \n",
      "Validation Fold 1/10:\n",
      "     Early stopping! No improvement in validation loss for 5 epochs.\n",
      "     Fold 1 - Train Loss: 0.5839, Train Accuracy: 0.8006\n",
      "     Fold 1 - Val Loss: 1.3696, Val Accuracy: 0.6050\n",
      "     \n",
      "Validation Fold 2/10:\n",
      "     Early stopping! No improvement in validation loss for 5 epochs.\n",
      "     Fold 2 - Train Loss: 0.1376, Train Accuracy: 0.9617\n",
      "     Fold 2 - Val Loss: 1.0763, Val Accuracy: 0.6950\n",
      "     \n",
      "Validation Fold 3/10:\n",
      "     Early stopping! No improvement in validation loss for 5 epochs.\n",
      "     Fold 3 - Train Loss: 0.3026, Train Accuracy: 0.9072\n",
      "     Fold 3 - Val Loss: 1.0686, Val Accuracy: 0.6750\n",
      "     \n",
      "Validation Fold 4/10:\n",
      "     Early stopping! No improvement in validation loss for 5 epochs.\n",
      "     Fold 4 - Train Loss: 0.3339, Train Accuracy: 0.8989\n",
      "     Fold 4 - Val Loss: 1.2655, Val Accuracy: 0.6500\n",
      "     \n",
      "Validation Fold 5/10:\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters\n",
    "\n",
    "n_targ = len(np.unique(y)) # Number of unique targets\n",
    "class_names = np.unique(y) # Names of unique targets\n",
    "\n",
    "# Initialize dictionaries and lists to store metrics\n",
    "all_test_splits_metrics = {} # Dictionary to store fold metrics for each test split\n",
    "\n",
    "# Storing metrics across test splits\n",
    "default_confmatrix_all = np.zeros((n_targ, n_targ, test_splits)) # all confusion matrices generated from the default model on test set, before averaging across test folds\n",
    "reward_confmatrix_all = np.zeros((n_targ, n_targ, test_splits)) # all confusion matrices generated from the default model on test set, before averaging across test folds\n",
    "\n",
    "default_test_accuracy_history = []\n",
    "default_val_accuracy_history = []\n",
    "\n",
    "reward_test_accuracy_history = []\n",
    "reward_val_accuracy_history = []\n",
    "\n",
    "for i in range(test_splits):\n",
    "    print(f\"\\nTest Split {i + 1}/{test_splits}:\")\n",
    "    \n",
    "    # Set seeds for reproducibility\n",
    "    np.random.seed(i)\n",
    "    torch.manual_seed(i) # for CPU\n",
    "    torch.cuda.manual_seed_all(i) # for GPU\n",
    "    \n",
    "    # Shuffle indices\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Split indices into training and test sets\n",
    "    train_indices, test_indices = train_test_split(indices, test_size=224)\n",
    "    \n",
    "    # Further split train_indices into two training sets\n",
    "    train_default_indices, train_reward_indices = train_test_split(train_indices, test_size=2000)\n",
    "\n",
    "    # Use these indices to create data splits\n",
    "    X_default, y_default = X[train_default_indices], y_num[train_default_indices]\n",
    "    X_reward, y_reward = X[train_reward_indices], y_num[train_reward_indices]\n",
    "    X_test, y_test = X[test_indices], y_num[test_indices]\n",
    "    \n",
    "    # Train default model. Select highest performing model across validation sets\n",
    "    print('Training default model...')\n",
    "    default_model, default_validation_acc, fold_metrics_default = train_default(X_default, y_default, device = torch.device(device))\n",
    "    default_val_accuracy_history.append(default_validation_acc)\n",
    "    \n",
    "    # Evaluate performance of default on held out test set\n",
    "    default_test_accuracy, default_confmatrix = evaluate_default(X_test, y_test, default_model, device = torch.device(device))\n",
    "    default_test_accuracy_history.append(default_test_accuracy)\n",
    "    default_confmatrix_all[:,:,i] = default_confmatrix\n",
    "    \n",
    "    # Initialize reward model with default model weights. Train reward model. Select highest performing model across validation sets\n",
    "    print('\\nTraining reward model...')\n",
    "    reward_model, reward_validation_acc, fold_metrics_reward = train_reward(X_reward, y_reward, default_model, device = torch.device(device)) \n",
    "    reward_val_accuracy_history.append(reward_validation_acc)\n",
    "    \n",
    "    _, _, reward_test_accuracy, reward_confmatrix = evaluate_reward_model(X_test, y_test, reward_model, eval_mode = True, device_eval=torch.device(device))\n",
    "    print(f'Reward test accuracy: {reward_test_accuracy*100:.2f}%')\n",
    "    reward_test_accuracy_history.append(reward_test_accuracy)\n",
    "    reward_confmatrix_all[:,:,i] = reward_confmatrix\n",
    "    \n",
    "    # Store fold metrics for this test split\n",
    "    all_test_splits_metrics[f'Test Split {i+1}'] = {\n",
    "        'Default': fold_metrics_default,\n",
    "        'Reward': fold_metrics_reward\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd92ec-48e8-4d88-857b-43eca96ee516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_avg_performance_bar_chart(default_test_accuracy_history, reward_test_accuracy_history)\n",
    "\n",
    "# Class-wise bar chart\n",
    "plot_class_wise_bar_chart(default_confmatrix_all, reward_confmatrix_all, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f51aa3-c381-4fdf-a133-6ca7678b0d1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot default clustered confusion matrix\n",
    "test_acc_mean = np.mean(default_test_accuracy_history)\n",
    "val_acc_mean = np.mean(default_val_accuracy_history)\n",
    "plot_average_clustered_conf_matrix(default_confmatrix_all, test_acc_mean, val_acc_mean, class_labels)\n",
    "\n",
    "# Plot reward clustered confusion matrix\n",
    "test_acc_mean = np.mean(reward_test_accuracy_history)\n",
    "val_acc_mean = np.mean(reward_val_accuracy_history)\n",
    "plot_average_clustered_conf_matrix(reward_confmatrix_all, test_acc_mean, val_acc_mean, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1f4e9-5b50-450c-b237-f26f0cadf2e1",
   "metadata": {},
   "source": [
    "# Analysis 2: Informative Prior Policy Accelerates Training of Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d219ce8-adc8-4c5a-84ac-42da500d51d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "n_targ = len(np.unique(y)) # Number of unique targets\n",
    "class_names = np.unique(y) # Names of unique targets\n",
    "\n",
    "# Initialize dictionaries and lists to store metrics\n",
    "all_test_splits_metrics_no_prior = {} # Dictionary to store fold metrics for each test split\n",
    "\n",
    "# Storing metrics across test splits\n",
    "reward_no_prior_confmatrix_all = np.zeros((n_targ, n_targ, test_splits)) # all confusion matrices generated from the default model on test set, before averaging across test folds\n",
    "\n",
    "reward_test_accuracy_history_no_prior = []\n",
    "reward_val_accuracy_history_no_prior = []\n",
    "\n",
    "for i in range(test_splits):\n",
    "    print(f\"\\nTest Split {i + 1}/{test_splits}:\")\n",
    "    \n",
    "    # Set seeds for reproducibility\n",
    "    np.random.seed(i)\n",
    "    torch.manual_seed(i) # for CPU\n",
    "    torch.cuda.manual_seed_all(i) # for GPU\n",
    "    \n",
    "    # Shuffle indices\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Split indices into training and test sets\n",
    "    train_indices, test_indices = train_test_split(indices, test_size=224)\n",
    "    \n",
    "    # Further split train_indices into two training sets\n",
    "    train_default_indices, train_reward_indices = train_test_split(train_indices, test_size=2000)\n",
    "\n",
    "    # Use these indices to create data splits\n",
    "    X_default, y_default = X[train_default_indices], y_num[train_default_indices]\n",
    "    X_reward, y_reward = X[train_reward_indices], y_num[train_reward_indices]\n",
    "    X_test, y_test = X[test_indices], y_num[test_indices]\n",
    "        \n",
    "     # Initialize reward model without prior policy. Train reward model. Select highest performing model across validation sets\n",
    "    print('\\nTraining reward model without prior policy...')\n",
    "    reward_model_no_prior, reward_validation_acc_no_prior, fold_metrics_reward_no_prior = train_reward_no_prior(X_reward, y_reward, device = torch.device(device)) \n",
    "    reward_val_accuracy_history_no_prior.append(reward_validation_acc_no_prior)\n",
    "    \n",
    "    print('Evaluating reward model without prior policy...')\n",
    "    _, _, reward_test_accuracy_no_prior, reward_no_prior_confmatrix = evaluate_reward_model(X_test, y_test, reward_model_no_prior, eval_mode = True, device_eval=torch.device(device))\n",
    "    print(f'Reward without prior policy test accuracy: {reward_test_accuracy_no_prior*100:.2f}%')\n",
    "    reward_test_accuracy_history_no_prior.append(reward_test_accuracy_no_prior)\n",
    "    reward_no_prior_confmatrix_all[:,:,i] = reward_no_prior_confmatrix\n",
    "    \n",
    "    # Store fold metrics for this test split\n",
    "    all_test_splits_metrics_no_prior[f'Test Split {i+1}'] = {\n",
    "        'Reward no prior': fold_metrics_reward_no_prior\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cae1c2-4777-47c9-bc87-597b287dfd58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bar chart\n",
    "plot_triple_comparison_bar_chart(default_test_accuracy_history, reward_test_accuracy_history, reward_test_accuracy_history_no_prior, third_label = 'Reward without\\nPrior Policy', third_color = 'orange', chance = 3.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f1554-7280-451f-96dc-95d5a04adf2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# average training loss versus epochs\n",
    "average_values_reward, sem_values_reward, epochs_reward = calculate_average_metric(all_test_splits_metrics, 'Reward', 'Training Loss')\n",
    "average_values_default, sem_values_default, epochs_default = calculate_average_metric(all_test_splits_metrics, 'Default', 'Training Loss')\n",
    "average_values_noprior, sem_values_noprior, epochs_noprior = calculate_average_metric(all_test_splits_metrics_no_prior, 'Reward no prior', 'Training Loss')\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "plt.plot(epochs_default, average_values_default, color='gray', marker='o', label='Default')\n",
    "plt.fill_between(epochs_default, average_values_default - sem_values_default, average_values_default + sem_values_default, color='gray', alpha=0.2)\n",
    "\n",
    "plt.plot(epochs_reward, average_values_reward, color='steelblue', marker='o', label='Reward')\n",
    "plt.fill_between(epochs_reward, average_values_reward - sem_values_reward, average_values_reward + sem_values_reward, color='steelblue', alpha=0.2)\n",
    "\n",
    "plt.plot(epochs_noprior, average_values_noprior, color='orange', marker='o', label='Reward without prior policy')\n",
    "plt.fill_between(epochs_noprior, average_values_noprior - sem_values_noprior, average_values_noprior + sem_values_noprior, color='orange', alpha=0.2)\n",
    "\n",
    "plt.xlabel('Normalized Epochs', fontsize=18)\n",
    "plt.ylabel(f'Average Training Loss', fontsize=18)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.title(f'Average Training Loss', fontsize=22)\n",
    "plt.legend(frameon = False, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79daa1-81d4-4e9f-8e21-eead9eea4eb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# average validation accuracy versus epochs\n",
    "average_values_reward, sem_values_reward, epochs_reward = calculate_average_metric(all_test_splits_metrics, 'Reward', 'Validation Accuracy')\n",
    "average_values_default, sem_values_default, epochs_default = calculate_average_metric(all_test_splits_metrics, 'Default', 'Validation Accuracy')\n",
    "average_values_noprior, sem_values_noprior, epochs_noprior = calculate_average_metric(all_test_splits_metrics_no_prior, 'Reward no prior', 'Validation Accuracy')\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "plt.plot(epochs_reward, average_values_reward, color='steelblue', marker='o', label='Reward')\n",
    "plt.fill_between(epochs_reward, average_values_reward - sem_values_reward, average_values_reward + sem_values_reward, color='steelblue', alpha=0.2)\n",
    "\n",
    "plt.plot(epochs_default, average_values_default, color='gray', marker='o', label='Default')\n",
    "plt.fill_between(epochs_default, average_values_default - sem_values_default, average_values_default + sem_values_default, color='gray', alpha=0.2)\n",
    "\n",
    "plt.plot(epochs_noprior, average_values_noprior, color='orange', marker='o', label='Reward without\\nprior policy')\n",
    "plt.fill_between(epochs_noprior, average_values_noprior - sem_values_noprior, average_values_noprior + sem_values_noprior, color='orange', alpha=0.2)\n",
    "\n",
    "plt.xlabel('Normalized Epochs', fontsize=18)\n",
    "plt.ylabel(f'Average Val Accuracy (%)', fontsize=18)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.title(f'Average Validation Accuracy', fontsize=22)\n",
    "plt.legend(frameon = False, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e08574-8a7b-40c0-9164-c3f799f0f194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train val acc for default, reward, and reward without prior policy\n",
    "\n",
    "average_values_reward, sem_values_reward, normalized_epochs = calculate_average_metric(all_test_splits_metrics, 'Reward', 'Training Accuracy')\n",
    "average_values_default, sem_values_default_train, _ = calculate_average_metric(all_test_splits_metrics, 'Default', 'Training Accuracy')\n",
    "average_values_noprior, sem_values_noprior, epochs_noprior = calculate_average_metric(all_test_splits_metrics_no_prior, 'Reward no prior', 'Training Accuracy')\n",
    "\n",
    "average_values_reward_val, sem_values_reward_val, normalized_epochs = calculate_average_metric(all_test_splits_metrics, 'Reward', 'Validation Accuracy')\n",
    "average_values_default_val, sem_values_default_val, _ = calculate_average_metric(all_test_splits_metrics, 'Default', 'Validation Accuracy')\n",
    "average_values_noprior_val, sem_values_noprior_val, epochs_noprior = calculate_average_metric(all_test_splits_metrics_no_prior, 'Reward no prior', 'Validation Accuracy')\n",
    "\n",
    "metrics_data = [\n",
    "    (average_values_default, sem_values_default, average_values_default_val, sem_values_default_val),\n",
    "    (average_values_reward, sem_values_reward, average_values_reward_val, sem_values_reward_val),\n",
    "    (average_values_noprior, sem_values_noprior, average_values_noprior_val, sem_values_noprior_val)\n",
    "]\n",
    "\n",
    "titles = ['Default Model', 'Reward Model', 'Reward Model without Prior Policy']\n",
    "colors = ['gray', 'steelblue', 'orange']\n",
    "\n",
    "plot_ablation_training_validation_accuracy(normalized_epochs, metrics_data, titles, colors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c682d0-9555-4fb0-8ebf-8535f4168fd4",
   "metadata": {},
   "source": [
    "# Analysis 3: Ensembling Reward Models Enhances Predictive Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c33b1f-1fd2-4402-b31f-2e30851577a1",
   "metadata": {},
   "source": [
    "### Plot confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb07b0-3ed7-4d53-946d-d8c4d12770ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "n_targ = len(np.unique(y)) # Number of unique targets\n",
    "class_names = np.unique(y) # Names of unique targets\n",
    "\n",
    "# Initialize dictionaries and lists to store metrics\n",
    "all_test_splits_metrics = {} # Dictionary to store fold metrics for each test split\n",
    "\n",
    "# Storing metrics across test splits\n",
    "default_confmatrix_all = np.zeros((n_targ, n_targ, test_splits))\n",
    "ensemble_reward_confmatrix_all = np.zeros((n_targ, n_targ, test_splits))\n",
    "\n",
    "default_test_accuracy_history = []\n",
    "default_val_accuracy_history = []\n",
    "\n",
    "ensemble_reward_test_accuracy_history = []\n",
    "ensemble_reward_val_accuracy_history = []\n",
    "\n",
    "for i in range(test_splits):\n",
    "    print(f\"\\nTest Split {i + 1}/{test_splits}:\")\n",
    "    \n",
    "    # Set seeds for reproducibility\n",
    "    np.random.seed(i)\n",
    "    torch.manual_seed(i) # for CPU\n",
    "    torch.cuda.manual_seed_all(i) # for GPU\n",
    "    \n",
    "    # Shuffle indices\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Split indices into training and test sets\n",
    "    train_indices, test_indices = train_test_split(indices, test_size=224)\n",
    "    \n",
    "    # Further split train_indices into two training sets\n",
    "    train_default_indices, train_reward_indices = train_test_split(train_indices, test_size=2000)\n",
    "\n",
    "    # Use these indices to create data splits\n",
    "    X_default, y_default = X[train_default_indices], y_num[train_default_indices]\n",
    "    X_reward, y_reward = X[train_reward_indices], y_num[train_reward_indices]\n",
    "    X_test, y_test = X[test_indices], y_num[test_indices]\n",
    "    \n",
    "    # Train default model. Select highest performing model across validation sets\n",
    "    print('Training default model...')\n",
    "    default_model, default_validation_acc, fold_metrics_default = train_default(X_default, y_default, device = torch.device(device))\n",
    "    default_val_accuracy_history.append(default_validation_acc)\n",
    "    \n",
    "    # Evaluate performance of default on held out test set\n",
    "    print('Evaluating default model...')\n",
    "    default_test_accuracy, default_confmatrix = evaluate_default(X_test, y_test, default_model, device = torch.device(device))\n",
    "    default_test_accuracy_history.append(default_test_accuracy)\n",
    "    default_confmatrix_all[:,:,i] = default_confmatrix\n",
    "    \n",
    "    # Initialize ensemble reward model with default model weights. Train reward model. Collect an ensemble of 10 models trained on each validation set.\n",
    "    print('\\nTraining reward models...')\n",
    "    reward_models, fold_metrics_ensemble_reward = train_reward_ensemble(X_reward, y_reward, default_model, device = torch.device(device)) # this needs to use cpu\n",
    "    print('reward_models keys', reward_models.keys())\n",
    "    \n",
    "    print('Evaluating ensemble of reward models')\n",
    "    _, ensemble_reward_test_accuracy, ensemble_reward_confmatrix = evaluate_reward_model_ensemble(X_test, y_test, reward_models, device_eval=torch.device(device))\n",
    "    print(f'Reward test accuracy: {ensemble_reward_test_accuracy*100:.2f}%')\n",
    "    ensemble_reward_test_accuracy_history.append(ensemble_reward_test_accuracy)\n",
    "    ensemble_reward_confmatrix_all[:,:,i] = ensemble_reward_confmatrix\n",
    "    \n",
    "    # Store fold metrics for this test split\n",
    "    all_test_splits_metrics[f'Test Split {i+1}'] = {\n",
    "        'Default': fold_metrics_default,\n",
    "        'Ensemble': fold_metrics_ensemble_reward\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9183e863-f497-4c7e-a6f3-63e85a261041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_triple_comparison_bar_chart(default_test_accuracy_history, reward_test_accuracy_history, ensemble_reward_test_accuracy_history, third_label = 'Ensemble', third_color = 'darkseagreen', chance = 3.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284fe851-ce2f-4a95-b16d-14a4b9a464f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_sorted_confusion_matrix(ensemble_reward_confmatrix_all, np.mean(ensemble_reward_test_accuracy_history), np.mean(ensemble_reward_val_accuracy_history), class_labels)\n",
    "plot_sorted_confusion_matrix(reward_confmatrix_all, np.mean(reward_test_accuracy_history), np.mean(reward_val_accuracy_history), class_labels)\n",
    "plot_sorted_confusion_matrix(default_confmatrix_all, np.mean(default_test_accuracy_history), np.mean(default_val_accuracy_history), class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81acf03-007f-4890-af4b-b095c9bd1567",
   "metadata": {},
   "source": [
    "### Accuracy versus reward mislabeling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db8687-168d-457c-897f-c1270d084473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "test_splits = 1 # This experiment takes a particularly long time\n",
    "n_targ = len(np.unique(y)) # Number of unique targets\n",
    "class_names = np.unique(y) # Names of unique targets\n",
    "\n",
    "default_test_accuracy_history = []\n",
    "default_val_accuracy_history = []\n",
    "\n",
    "reward_error = [0, 0.05, 0.1, 0.15, 0.2, 0.25]\n",
    "reward_test_accuracy_dict = {val: [] for val in reward_error}\n",
    "reward_val_accuracy_dict = {val: [] for val in reward_error}\n",
    "\n",
    "reward_ensemble_test_accuracy_dict = {val: [] for val in reward_error}\n",
    "reward_ensemble_val_accuracy_dict = {val: [] for val in reward_error}\n",
    "\n",
    "for i in range(test_splits):\n",
    "    print(f\"\\nTest Split {i + 1}/{test_splits}:\")\n",
    "    \n",
    "    # Set seeds for reproducibility\n",
    "    np.random.seed(i)\n",
    "    torch.manual_seed(i) # for CPU\n",
    "    torch.cuda.manual_seed_all(i) # for GPU\n",
    "    \n",
    "    # Shuffle indices\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Split indices into training and test sets\n",
    "    train_indices, test_indices = train_test_split(indices, test_size=224)\n",
    "\n",
    "    # Further split train_indices into two training sets\n",
    "    train_default_indices, train_reward_indices = train_test_split(train_indices, test_size=2000)\n",
    "\n",
    "    # Use these indices to create data splits\n",
    "    X_default, y_default = X[train_default_indices], y_num[train_default_indices]\n",
    "    X_reward, y_reward = X[train_reward_indices], y_num[train_reward_indices]\n",
    "    X_test, y_test = X[test_indices], y_num[test_indices]\n",
    "\n",
    "    # Train default model. Select highest performing model across validation sets\n",
    "    print('Training default model...')\n",
    "    default_model, default_validation_acc = train_default(X_default, y_default, device = torch.device(device))\n",
    "    default_val_accuracy_history.append(default_validation_acc)\n",
    "    \n",
    "    # Evaluate performance of default and reward models on held out test set \n",
    "    default_test_accuracy, default_confmatrix = evaluate_default(X_test, y_test, default_model, device = torch.device(device))\n",
    "    default_test_accuracy_history.append(default_test_accuracy)\n",
    "    \n",
    "    for index, p in enumerate(reward_error):    \n",
    "        for repeats in range(3):\n",
    "            \n",
    "            print('Reward error probability: ', p)\n",
    "            print(f'     Reward prob {repeats+1}/3:')\n",
    "            # Reward model\n",
    "            print('          Training reward model...')\n",
    "            reward_model, reward_validation_acc = train_reward_error(X_reward, y_reward, default_model, p, repeats, device = torch.device(device))\n",
    "            reward_val_accuracy_dict[p].append(reward_validation_acc)\n",
    "\n",
    "            _, _, reward_test_accuracy, reward_confmatrix = evaluate_reward_model(X_test, y_test, reward_model, eval_mode = True, device_eval=torch.device(device))\n",
    "            print(f'          Reward test acc: {reward_test_accuracy*100:.2f}%')\n",
    "            reward_test_accuracy_dict[p].append(reward_test_accuracy)\n",
    "            \n",
    "            # Reward ensemble model\n",
    "            print('          Training reward ensemble model...')\n",
    "            reward_ensemle_models, reward_ensemble_validation_acc = train_reward_error_ensemble(X_reward, y_reward, default_model, p, repeats, device = torch.device(device)) \n",
    "            reward_ensemble_val_accuracy_dict[p].append(reward_ensemble_validation_acc)\n",
    "\n",
    "            _, reward_ensemble_test_accuracy, reward_ensemble_confmatrix = evaluate_reward_model_ensemble(X_test, y_test, reward_ensemle_models, device_eval=torch.device(device))\n",
    "            print(f'          Reward ensemble test acc: {reward_ensemble_test_accuracy*100:.2f}%')\n",
    "            reward_ensemble_test_accuracy_dict[p].append(reward_ensemble_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528f0513-2bf4-4f5d-b4d4-a10d93e4d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_vs_reward_error(default_test_accuracy_history, reward_test_accuracy_dict, reward_ensemble_test_accuracy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18789c-a0a8-4760-ace4-d1e217c77f82",
   "metadata": {},
   "source": [
    "# Analysis 4: Predicting reward signal from neural activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5234ff-094f-435e-b14e-b99e4a24cfa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_name = 'data'\n",
    "file_name = 'feedback_data.pkl'\n",
    "\n",
    "# Define the full path\n",
    "full_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "with open(full_path, 'rb') as file:\n",
    "    incorrect_feedback, correct_feedback = pickle.load(file)\n",
    "print(\"Data successfully loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda486dc-730f-48b2-858e-a3cee39be7fc",
   "metadata": {},
   "source": [
    "### Plot Event related Potentials (ERPs) \n",
    "##### (note: this takes a few minutes to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f9100f-14ee-407c-9d61-5fa58543922b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_erp_b3_gaussiansmooth(incorrect_feedback, 'Incorrect', correct_feedback, 'Correct', 10, 0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b02f0a0-6628-4c18-9e81-d08c719b23c6",
   "metadata": {},
   "source": [
    "### Plot Relative Electrode Activity\n",
    "####  This plot will load from a picture since you don't have access to the libraries my lab uses to make plots like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a80ea0f-73b7-4776-8976-684188104197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_relative_electrode_strength(incorrect_feedback, correct_feedback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0becfec7-53ef-49f4-8685-d6f7e846ffac",
   "metadata": {},
   "source": [
    "### Plot hyperparameter tuning curve to select best value of n_components for PCA in Logistic Regression + PCA model\n",
    "#### Note: Plots in final project paper were created using 50 iterations for each n_components value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92232532-87d5-4289-a689-7f1d278ff630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "average_accuracies, sem_accuracies = n_components_tuning(incorrect_feedback, correct_feedback, n_components_range = np.arange(0.85, 0.99, 0.01), iterations = 1)\n",
    "plot_n_components_tuning(average_accuracies, sem_accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94555d1d-5f67-48ed-a176-e020b3d67214",
   "metadata": {},
   "source": [
    "### Assess performance of logistic regression + PCA model\n",
    "#### Note: Plots in final project paper were created using 100 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbbebed-4055-40a7-8eaa-a7c6406e233b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm_pre_avg, accuracy_history = train_logR_reward(incorrect_feedback, correct_feedback, n_targ = 2, iterations = 3, n_components = 0.92)\n",
    "plot_sorted_confusion_matrix(cm_pre_avg, np.mean(accuracy_history), val_acc_mean = None, class_labels = ['Incorrect', 'Correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dee4f4f-b8ca-4390-9aff-3445e5e890d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bravo Environment",
   "language": "python",
   "name": "gimletenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
